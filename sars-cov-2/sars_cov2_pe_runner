#!/usr/bin/env bash

SAMPLE=$1

# download the reference data
nextclade dataset get --name='sars-cov-2' --output-dir=$HOME/reference/nextclade-data/sars-cov-2

if [[ -n ${HOME}/pipeline/${SAMPLE}.tar ]]; then
    echo Starting ${SAMPLE} run

    # give us a place to work
    mkdir -p ${HOME}/pipeline/${SAMPLE}

    # build the pipeline
    python ${HOME}/pipeline-builder/sars-cov-2/build_sars_cov2_pe_pipeline.py \
        --cores 72 \
        --sample ${SAMPLE} \
        --work-dir ${HOME} \
        --reference-dir ${HOME}/reference/sars-cov-2 \
        --pipeline-dir ${HOME}/pipeline/${SAMPLE} \
        --stats-dir ${HOME}/pipeline/${SAMPLE} \
        --script ${HOME}/pipeline/${SAMPLE}/${SAMPLE}_runner \
        --temp-dir ${HOME}/stats/temp \
        --fastq-dir ${HOME}/pipeline/FASTQ \
        --caller bcftools \
        --aligner bwa \
        --preprocessor fastp \
        --sorter biobambam

    # run the pipeline
    bash ${HOME}/pipeline/${SAMPLE}/${SAMPLE}_runner >${HOME}/pipeline/${SAMPLE}/${SAMPLE}.log 2>&1

    # pack up the stuff and clean house
    # rm -f ${HOME}/pipeline/${SAMPLE}/${SAMPLE}_R1.trimmed.fastq.gz
    # rm -f ${HOME}/pipeline/${SAMPLE}/${SAMPLE}_R2.trimmed.fastq.gz

    cd ${HOME}/pipeline/
    tar cfz ${HOME}/pipeline/${SAMPLE}.tgz ./${SAMPLE}
    # rm -rf ${HOME}/pipeline/${SAMPLE}

    echo Finished ${SAMPLE} run
else
    echo "We have already processed sample ${SAMPLE}"
fi
