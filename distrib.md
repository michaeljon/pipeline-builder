# Notes and thoughts on distributing alignment

## Alignment

Ok, after having hacked through the alignment process over the weekend I've kinda come to the conclusion that using map/reduce or something like it isn't really the right idea. To make it really work would require an always-on BWA aligner (because of cache and index loading costs) that could listen on some IPC mechanism (probably a socket). I don't think we want to be in the game of forking and maintaining the BWA-MEM2 code (while fun and interesting, unless there's a serious competitive advantage, it's some very gnarly C code hand-tuned by Intel to work very well on their processors and takes explicit advantage of certain processor instruction sets being available)...

So, that leaves us with some other way to perform trimming, alignment, sorting, and duplicate marking (the "alignment" stuff). We can continue to keep a 72 core ec2 running and eat around 120 minutes wall time to get through the above steps. The alternative, and again we're back to figuring out the cost-benefit vs. time-to-align tradeoffs, is to distribute the work in larger chunks.

I took a run at doing a local FASTP trimming operation on the entire FASTQ, then partitioning the file into 64 chunks. The trimming has to happen on the entire FASTQ because of how FASTP determines adapter sequences. There's a chance that different sequences could be identified from different fragments leading to an inconsistent and incorrect alignment. The trimming process is limited to 16 threads (a FASTP limitation) and uses around 1260 wall clock seconds (21 minutes). I then used FASTP again to partition the file by disabling all trimming options (I couldn't successfully combine these two steps, FASTP would simply hang after running for a while) with a clock time of approximately 540 seconds (9 minutes).

The intermediate trimmed FASTQ pair can be deleted once the partitioning is completed. There's no real reason to serialize the partitioning operation as each partition pair could be sent to storage and queued to the next operation as soon as the partition is constructed. However, this would require a modification to FASTP because, while it does partition based on the number of assigned threads, there is no way to know that a partition is completed until the entire partioning oepration is complete. This means that the trimming and partioning operations, unless we can address the hang, will take about 1800 seconds (30 minutes) of wall time to execute.

The next step can be parallelized across many worker nodes. In the current experiment run on the "big" ec2 we're using, each partition takes approximately 90 seconds to align. The majority of this time is spent reading the index into memory. We can, and should, use the partition count and the ec2 processor count as input parameters to queueing and service models. It might be the case that dropping the number of partitions, say to 32, would result in a more balanced load / align tradeoff.

Once each partition is aligned is can immediately be sent on to be coordinate sorted, duplicate marked, and indexed. This process uses no additional input files and is limited only by the available threads and memory on the sorting node. Each partition in my experiment took about 150 wall clock seconds.

The final step before we can call variants is to reconstruct the complete aligned and sorted BAM from the individual BAM fragments. Each BAM fragment contains reads from across the genome. We can either scatter the fragment BAMS into intervals (about $64\text{ partitions}\times65\text{ intervals}$ resulting files), or we can recombine the partioning BAMs into a single file and partition after. The experiment I ran over the weekend produces a complete, aligned, sorted BAM (something I believe our customers might ask for) in about 1200 seconds (20 minutes). We would then push this BAM to long term storage for later processing.

## Variant calling

(This section will use the `chr1:1-50000000` interval as an example.)

Variant calling is inherently parallelizable. Once we have an aligned and sorted BAM we can create intervals of that BAM and run a variant calling process on the individual interval. `samtools` is used to create the interval files and their associated index. This scattering operation uses a different set of input rules but is otherwise configurable (chromosome "sizes" are the fixed input, interval sizes and an overfill factor are used to construct the actual per-interval file sizes). "Scattering" these files is a read-only operation on the source BAM and can be computed in parallel on a single compute node. Our current pipeline performs the interval creation and indexing by starting the process pairs as background jobs and waiting on them to complete. Each interval, run at 4 threads, takes approximately 35 seconds for BAM construction and 3 seconds for index construction. I expect the interval sizes to stay within a fairly small range since each interval is approximately the same size. However, the number of reads within a given interval may differ. (This might be an interesting research paper - what's the relationship to genome position vs. chromosome read distribution vs. coverage alignment)

The way we're calling variants right now (on the single ec2) is to create per-chromosome intervals of 50mbp ($\pm20\%$) and using those individual intervals as inputs to the GATK BQSR process. BQSR is a two-step process which first uses the BAM and various reference data, to construct a table of corrections. Those corrections are then applied to the BAM to create a quality-adjusted BAM. We should run some experiments to determine the value of this step as it's recommended for the GATK "best practices" workflow, but not all experiments use that workflow.

One thing to note about using GATK for the BQSR and variant calling process - GATK is single-threaded. Our current pipeline takes advantage of that by running many BQSR processes in parallel on a single large compute node. I think keeping a smaller cluster of these compute nodes that can run many BQSR processes simultaneously might be a better approach than using many very small nodes. Computing the BQSR table uses around 385 seconds and applying the BQSR to the resulting BAM uses 240 seconds. These processes must be run serially and operate on the same input file. One thing of interest is that the resulting BAM after BQSR application is $2x$ the size of the input BAM.

Each resulting quality-adjusted BAM is then passed to one of the variant calling operations (both are options to our pipeline): `bcftools mpileup`/`bcftools call` or `HaplotypeCaller`.

The `bcftools` caller has an option to specify the number of threads however that option is either ignored or doesn't work as defined. The calling process is single threaded. We currently run `mpileup` and pipe its output directly to `call` to reduce both the overall time and the temporary disk space needed. Variant calling is one of the most time-wise expensive operations. The pileup operation uses 100% of a single core while running and the linked call operation uses < 10%. Overall variant calling runs in about 360 seconds (6 minutes) per interval.

## Variant post-processing

We have a number of alternatives for post-call variant processing. My preferred model is to send each interval variant set to a process that reads the VCF and stores the resulting variant data on a per-position basis in a relational store. This option gives us a queryable database (using technology that we are all comfortable with) in which we can perform downstream variant analysis (searching, joining to known annotation stores, reconstructing full or partial VCF files).

Another alternative is to recombine all of the interval VCFs into a per-sample file and store that. Querying over the resulting VCF would require specialized storage models andq query languages. We could store the VCF long term and deliver it as-is to a customer or perform a just-in-time variant annotation and deliver that file. We might also perform the variant annotation and store that resulting VCF are our query target. However, we're back to the problem of having a specialized query language and storage model, plus we add in a staleness factor for later variant interpretation. That is, we would need to either be content that our annotations have a valid-at timestamp or be open to running an analysis followed by a "refresh" annotation. Again, my preference is to store this in a way that we can get current analysis and generate VCFs on an ad hoc basis. (We could also get tricky and version our annotation data so that it would be possible to "go back in time" to generate a VCF from a known reference set.)